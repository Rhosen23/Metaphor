{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INR9dll4pWDv",
        "outputId": "c61c3a94-e49e-4e9f-e78c-c76e53604a90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.22.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.40.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.2)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.29.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.22.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.19.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.22.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install datasets\n",
        "%pip install transformers\n",
        "%pip install peft\n",
        "%pip install evaluate\n",
        "%pip install scikit-learn\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from datasets import load_dataset, DatasetDict, Dataset\n",
        "from datasets import load_metric\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoConfig,\n",
        "    RobertaTokenizer,\n",
        "    RobertaForSequenceClassification,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer)\n",
        "access_token = \"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\"\n",
        "\n",
        "#sklearn for evaluation\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from turtle import pd\n",
        "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
        "import evaluate\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InwUJD_0pWDw",
        "outputId": "99b2e7bb-9827-4ddf-c177-d25ab2e07de9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1486: FutureWarning: The repository for Joanne/Metaphors_and_Analogies contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/Joanne/Metaphors_and_Analogies\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['corpus', 'id', 'set_id', 'label', 'sentence', 'A', 'B', 'A_position', 'B_position', '5-folds'],\n",
              "        num_rows: 180\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['corpus', 'id', 'set_id', 'label', 'sentence', 'A', 'B', 'A_position', 'B_position', '5-folds'],\n",
              "        num_rows: 36\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['corpus', 'id', 'set_id', 'label', 'sentence', 'A', 'B', 'A_position', 'B_position', '5-folds'],\n",
              "        num_rows: 144\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "access_token = \"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\"\n",
        "# Load the dataset\n",
        "dataset = load_dataset('Joanne/Metaphors_and_Analogies','Pairs_Jankowiac_random_split')\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdeluj4YpWDx",
        "outputId": "a5fb36a3-4005-4a93-af94-1a2874e6136b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['corpus', 'id', 'set_id', 'label', 'sentence', 'A', 'B', 'A_position', 'B_position', '5-folds'],\n",
            "    num_rows: 180\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# Get the first row of the dataset\n",
        "first_row = dataset['train']\n",
        "\n",
        "# Print the first row\n",
        "print(first_row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX5gVEJnpWDx",
        "outputId": "3903ca69-9377-47fc-fbfe-8b2e66c5e98f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 2, 1, 1, 0, 0, 2, 1, 1, 2, 0, 1, 2, 0, 0, 1, 0, 2, 0, 2, 2,\n",
              "       2, 1, 0, 0, 0, 0, 2, 2, 0, 1, 0, 1, 2, 0, 0, 1, 1, 1, 0, 1, 0, 2,\n",
              "       0, 1, 0, 0, 0, 1, 0, 2, 2, 0, 0, 0, 0, 2, 0, 2, 1, 2, 1, 1, 2, 2,\n",
              "       1, 0, 1, 1, 0, 2, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 2, 2, 2, 0, 0, 0,\n",
              "       0, 2, 0, 1, 2, 2, 1, 0, 1, 0, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1,\n",
              "       2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 0, 1, 1, 1, 1, 2, 0, 0, 1, 1, 0, 2,\n",
              "       2, 1, 1, 2, 2, 1, 0, 2, 2, 1, 0, 1, 1, 0, 2, 1, 0, 1, 0, 0, 0, 1,\n",
              "       0, 2, 1, 0, 2, 0, 1, 0, 0, 1, 2, 1, 2, 0, 0, 0, 1, 0, 0, 2, 2, 0,\n",
              "       2, 0, 0, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# assume 'dataset' is your dataset object\n",
        "label_array = np.array(dataset['train']['label'])\n",
        "\n",
        "label_dtype = label_array.dtype\n",
        "\n",
        "label_array"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = 'roberta-base'\n",
        "\n",
        "id2label = {0: \"Anomaly\", 1: \"literal\", 2 : \"metaphor\"}\n",
        "label2id = {\"Anomaly\":0, \"literal\":1, \"metaphor\":2}\n",
        "\n",
        "\n",
        "model_name = 'roberta-base'\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
        "\n",
        "model.config.id2label = id2label\n",
        "model.config.label2id = label2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDBk3-xikTBx",
        "outputId": "651d17a6-11f2-42d0-c5b8-714437e850d5"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVtI8TfTOCJR",
        "outputId": "eb891519-dc36-4777-a7a8-64d5111b17b7"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RobertaForSequenceClassification(\n",
            "  (roberta): RobertaModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
            "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (classifier): RobertaClassificationHead(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq5X_8Z3pWDy",
        "outputId": "d2e1169f-cd7a-42fb-d316-d1271b72b36e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['corpus', 'id', 'set_id', 'label', 'sentence', 'A', 'B', 'A_position', 'B_position', '5-folds', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 180\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['corpus', 'id', 'set_id', 'label', 'sentence', 'A', 'B', 'A_position', 'B_position', '5-folds', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 36\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['corpus', 'id', 'set_id', 'label', 'sentence', 'A', 'B', 'A_position', 'B_position', '5-folds', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 144\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ],
      "source": [
        "# create tokenize function\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# add pad token if none exists\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    # extract text\n",
        "    text = examples[\"sentence\"]\n",
        "\n",
        "    #tokenize and truncate text\n",
        "    tokenizer.truncation_side = \"left\"\n",
        "    tokenized_inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"np\",\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "    return tokenized_inputs\n",
        "\n",
        "\n",
        "# tokenize training and validation datasets\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tM93j-HbN-C_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "4AH-jFNspWDy"
      },
      "outputs": [],
      "source": [
        "# create data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHrMF3eTpWDz",
        "outputId": "8f37cec7-c72e-4566-f036-7834b43ca82c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Untrained model predictions:\n",
            "----------------------------\n",
            "It was good. - Anomaly\n",
            "Not a fan, don't recommed. - literal\n",
            "Better than the first one. - Anomaly\n",
            "This is not worth watching even once. - literal\n",
            "This one is a pass. - metaphor\n"
          ]
        }
      ],
      "source": [
        "# define list of examples\n",
        "text_list = [\"It was good.\", \"Not a fan, don't recommed.\", \"Better than the first one.\", \"This is not worth watching even once.\", \"This one is a pass.\"]\n",
        "\n",
        "print(\"Untrained model predictions:\")\n",
        "print(\"----------------------------\")\n",
        "for text in text_list:\n",
        "    # tokenize text\n",
        "    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(model.device)\n",
        "    # compute logits\n",
        "    logits = model(inputs).logits\n",
        "    # convert logits to label\n",
        "    predictions = torch.argmax(logits)\n",
        "\n",
        "    print(text + \" - \" + id2label[predictions.tolist()])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "peft_config = LoraConfig(task_type=\"SEQ_CLS\",\n",
        "                        r=4,\n",
        "                        lora_alpha=32,\n",
        "                        lora_dropout=0.01,\n",
        "                        target_modules=['classifier.dense'])"
      ],
      "metadata": {
        "id": "9qQIfW7Ok_JX"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvUs8rwXpWDz",
        "outputId": "aae253b5-52cd-4c03-b0c2-0d11c639d23f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='SEQ_CLS', inference_mode=False, r=4, target_modules={'q_lin'}, lora_alpha=32, lora_dropout=0.01, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ],
      "source": [
        "peft_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKie0yDfpWD0",
        "outputId": "793c18d6-7991-42db-fb52-3aa108cdfb7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 629,763 || all params: 67,585,542 || trainable%: 0.9318013607111414\n"
          ]
        }
      ],
      "source": [
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "hYTn-djLpWD0"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "lr = 1e-4\n",
        "batch_size = 8\n",
        "num_epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXlHB72OpWDz",
        "outputId": "1e86acb4-0d40-42e2-e33d-7056c3ac9072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 全局定义度量工具\n",
        "accuracy_metric = load_metric(\"accuracy\")\n",
        "f1_scores = []\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
        "    accuracy_result = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "    f1_scores.append(f1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_result['accuracy'],  # 确保键名正确\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "Jy9ZVOfZpWD0"
      },
      "outputs": [],
      "source": [
        "# define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_checkpoint + \"-lora-text-classification\",\n",
        "    learning_rate=lr,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"tensorboard\",  # 开启TensorBoard日志记录\n",
        "    logging_dir=\"./logs\",  # 指定日志文件夹\n",
        "    logging_strategy=\"steps\",  # 日志记录策略：按步骤\n",
        "    logging_steps=8,  # 每10步记录一次日志\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "b3YBaUnbpWD0"
      },
      "outputs": [],
      "source": [
        "# creater trainer object\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator, # this will dynamically pad examples in each batch to be equal length\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "id": "DmCoJLuPtnGx",
        "outputId": "2f1e4013-b576-4d24-b437-c28dcc6dabf5"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [460/460 00:25, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.097500</td>\n",
              "      <td>1.050579</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.372222</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.454167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.049100</td>\n",
              "      <td>0.965508</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.375975</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.456798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.972700</td>\n",
              "      <td>0.841939</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.802778</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.699228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.851000</td>\n",
              "      <td>0.667357</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.880800</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.836786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.720500</td>\n",
              "      <td>0.587198</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.850529</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.808615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.614300</td>\n",
              "      <td>0.527127</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.827381</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.522000</td>\n",
              "      <td>0.487976</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.839744</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.806397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.400200</td>\n",
              "      <td>0.477824</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.839744</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.806397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.446800</td>\n",
              "      <td>0.459182</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.860119</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.832598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.374800</td>\n",
              "      <td>0.454741</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.841204</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.802364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.402400</td>\n",
              "      <td>0.453201</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.841204</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.802364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.502200</td>\n",
              "      <td>0.449475</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.841204</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.802364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.389700</td>\n",
              "      <td>0.460272</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.841204</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.802364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.386700</td>\n",
              "      <td>0.460059</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.841204</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.802364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.351500</td>\n",
              "      <td>0.445623</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.841204</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.802364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.291500</td>\n",
              "      <td>0.445408</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.841204</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.802364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.266900</td>\n",
              "      <td>0.465500</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.841204</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.802364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.251400</td>\n",
              "      <td>0.453360</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.841204</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.802364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.259800</td>\n",
              "      <td>0.447598</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.841204</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.802364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.281600</td>\n",
              "      <td>0.447639</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.841204</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.802364</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=460, training_loss=0.5250359143899834, metrics={'train_runtime': 25.88, 'train_samples_per_second': 139.104, 'train_steps_per_second': 17.774, 'total_flos': 7702001737200.0, 'train_loss': 0.5250359143899834, 'epoch': 20.0})"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow1qxvE61_uJ",
        "outputId": "c15b8e75-bc8e-4110-c261-e612d435b69f"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4541666666666666,\n",
              " 0.45679770679770676,\n",
              " 0.6992283950617284,\n",
              " 0.836785731713268,\n",
              " 0.8086151368760065,\n",
              " 0.7777777777777778,\n",
              " 0.8063973063973064,\n",
              " 0.8063973063973064,\n",
              " 0.8325984714873603,\n",
              " 0.8023636991028295,\n",
              " 0.8023636991028295,\n",
              " 0.8023636991028295,\n",
              " 0.8023636991028295,\n",
              " 0.8023636991028295,\n",
              " 0.8023636991028295,\n",
              " 0.8023636991028295,\n",
              " 0.8023636991028295,\n",
              " 0.8023636991028295,\n",
              " 0.8023636991028295,\n",
              " 0.8023636991028295]"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the F1 scores over time\n",
        "import matplotlib.pyplot as plt\n",
        "# Define the epoch numbers and F1 scores\n",
        "epochs = range(1, 21)\n",
        "\n",
        "# Plot the F1 scores against the epoch numbers\n",
        "plt.plot(epochs, f1_scores[0:20], 'bo-')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('F1 Score over Time')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "mr2VLOGT0KTV",
        "outputId": "4dd1fd8b-74bb-4060-95eb-d2572ebfe2df"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}